{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Descriptors import MolLogP\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "import sys\n",
    "import multiprocessing\n",
    "from standardiser import break_bonds, neutralise, rules, unsalt\n",
    "from standardiser.utils import StandardiseException, sanity_check\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "def warn(*args, **kwargs):\n",
    "    pass \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn = warn\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import sys\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import csv\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import _pickle as cPickle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit    \n",
    "import bz2\n",
    "from glob import glob\n",
    "import _pickle as cPickle\n",
    "import pickle\n",
    "# Draw.DrawingOptions.atomLabelFontFace = \"DejaVu Sans\"\n",
    "# Draw.DrawingOptions.atomLabelFontSize = 18\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# Function to read Excel file into DataFrame\n",
    "def load_excel_to_df(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    return df\n",
    "\n",
    "# Convert strings back to lists of integers\n",
    "def string_to_list(bit_string):\n",
    "    if isinstance(bit_string, str):\n",
    "        return list(map(int, bit_string.strip('[]').split(', ')))\n",
    "    else:\n",
    "        return bit_string\n",
    "\n",
    "# Load Excel file\n",
    "train_df = load_excel_to_df(r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Train_set_Dermal_balanced_with_fingerprints_sorted_with_RDKit_and_CDK_features.xlsx\")\n",
    "\n",
    "# Apply the string-to-list conversion for the fingerprint columns\n",
    "fingerprint_columns = ['Morgan_Descriptors', 'MACCS_Descriptors', 'APF_Descriptors']\n",
    "for col in fingerprint_columns:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].apply(string_to_list)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} not found in Excel file!\")\n",
    "\n",
    "# Define combined_df as train_df\n",
    "combined_df = train_df\n",
    "\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine_df= combined_df.sort_values(['Outcome'], ascending=True)\n",
    "combined_df['RowID'] = combined_df.index\n",
    "combined_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "outcomes = np.unique(combined_df['Outcome'])\n",
    "le.fit(outcomes)\n",
    "y = le.transform(combined_df['Outcome'])\n",
    "\n",
    "# Hasil\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(\"Classes                          : \", classes)\n",
    "print(\"Number of cpds in each class     : \", counts)\n",
    "print(\"Total number of cpds             : \", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.Series(le.transform(combined_df['Outcome']))  # Sama dengan y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = S.hist(bins=np.arange(-0.5,5))\n",
    "ax.set_xticks(range(0,5))\n",
    "#info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y = np.int32(S)  # pastikan S sudah didefinisikan\n",
    "\n",
    "# Fingerprint arrays\n",
    "x_maccs = np.array(list(combined_df['MACCS_Descriptors']))\n",
    "x_morgan = np.array(list(combined_df['Morgan_Descriptors']))\n",
    "x_apf = np.array(list(combined_df['APF_Descriptors']))  # ditambahkan APF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# 1️⃣ Define features and target\n",
    "# ==========================\n",
    "# x_morgan, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# 2️⃣ Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_morgan.shape[1], x_morgan.shape[1] // 2, x_morgan.shape[1] // 4, x_morgan.shape[1] // 12, x_morgan.shape[1] // 10,\n",
    "        x_morgan.shape[1] // 7, x_morgan.shape[1] // 5, x_morgan.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# 3️⃣ Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 4️⃣ Cross-validation for performance reporting\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# 5️⃣ Loop CV to evaluate performance\n",
    "# ==========================\n",
    "for train_idx, test_idx in cv.split(x_morgan, y):\n",
    "    X_train, X_test = x_morgan[train_idx], x_morgan[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # GridSearchCV untuk hyperparameter terbaik\n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,  \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    # Prediksi fold test\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# 6️⃣ Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# 7️⃣ Train final model on full dataset\n",
    "# ==========================\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_morgan, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# 8️⃣ Save final model\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_path = os.path.join(model_folder, 'FDAMDD_rf_morgan.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# ==========================\n",
    "# 9️⃣ Save CV metrics report\n",
    "# ==========================\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_morgan_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACCS_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_maccs, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_maccs.shape[1], x_maccs.shape[1] // 2, x_maccs.shape[1] // 4,\n",
    "        x_maccs.shape[1] // 12, x_maccs.shape[1] // 10,\n",
    "        x_maccs.shape[1] // 7, x_maccs.shape[1] // 5, x_maccs.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress bar\n",
    "# ==========================\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_maccs, y), total=cv.get_n_splits(), desc=\"Outer CV folds\")):\n",
    "    X_train, X_test = x_maccs[train_idx], x_maccs[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"Training final model on full dataset...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_final.fit(x_maccs, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(model_folder, 'FDAMDD_rf_macckeys.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# ==========================\n",
    "# Save CV metrics report\n",
    "# ==========================\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_macckeys_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APF_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_apf, y sudah didefinisikan sebelumnya\n",
    "# Pastikan y = np.int32(S)\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_features\": [\n",
    "        x_apf.shape[1], x_apf.shape[1] // 2, x_apf.shape[1] // 4,\n",
    "        x_apf.shape[1] // 12, x_apf.shape[1] // 10,\n",
    "        x_apf.shape[1] // 7, x_apf.shape[1] // 5, x_apf.shape[1] // 3\n",
    "    ],\n",
    "    \"n_estimators\": [10, 100, 300, 500],\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress bar\n",
    "# ==========================\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_apf, y), total=cv.get_n_splits(), desc=\"Outer CV folds\")):\n",
    "    X_train, X_test = x_apf[train_idx], x_apf[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'CV {k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"Training final model on full dataset...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_final.fit(x_apf, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics report\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_rf_apf.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final Random Forest model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_rf_apf_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_XBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_morgan, y sudah didefinisikan sebelumnya\n",
    "# Pastikan y = np.int32(S) jika perlu\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_morgan, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_morgan[train_idx], x_morgan[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset with GridSearchCV...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_morgan, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_morgan.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_morgan_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACCS_XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_maccs, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation for MACCS features...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_maccs, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_maccs[train_idx], x_maccs[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics for MACCS ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset (MACCS features)...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_maccs, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_maccs.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_maccs_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APF_XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# x_apf, y sudah didefinisikan sebelumnya\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid untuk XGBoost\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# 10-fold CV\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "confusion_matrices = []\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Outer CV loop dengan progress\n",
    "# ==========================\n",
    "print(\"Starting 10-fold cross-validation for APF features...\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(x_apf, y), total=10, desc=\"CV Folds\")):\n",
    "    X_train, X_test = x_apf[train_idx], x_apf[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "    ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "    \n",
    "    print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================\n",
    "# Report metrics\n",
    "# ==========================\n",
    "cv_metrics = {\n",
    "    \"Accuracy\": np.mean(accuracies),\n",
    "    \"AUC\": np.mean(auc_scores),\n",
    "    \"Precision\": np.mean(precisions),\n",
    "    \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "    \"F1\": np.mean(f1_scores),\n",
    "    \"Specificity\": np.mean(specificities),\n",
    "    \"PPV\": np.mean(ppvs),\n",
    "    \"NPV\": np.mean(npvs),\n",
    "    \"CCR\": np.mean(ccrs)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 10-Fold CV Metrics for APF ===\")\n",
    "for k, v in cv_metrics.items():\n",
    "    print(f'{k}: {v:.4f}')\n",
    "\n",
    "# ==========================\n",
    "# Fit final model di seluruh dataset\n",
    "# ==========================\n",
    "print(\"\\nTraining final XGBoost model on full dataset (APF features)...\")\n",
    "grid_final = GridSearchCV(\n",
    "    estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=paramgrid,\n",
    "    scoring=kappa_scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_final.fit(x_apf, y)\n",
    "final_model = grid_final.best_estimator_\n",
    "\n",
    "# ==========================\n",
    "# Save final model & metrics\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_folder, 'Dermal_xgb_apf.pkl')\n",
    "joblib.dump(final_model, model_path, compress=9)\n",
    "print(\"Final XGBoost model saved successfully!\")\n",
    "\n",
    "# Save CV metrics\n",
    "metrics_df = pd.DataFrame([cv_metrics])\n",
    "metrics_path = os.path.join(model_folder, 'Dermal_xgb_apf_CV_metrics.xlsx')\n",
    "metrics_df.to_excel(metrics_path, index=False)\n",
    "print(f\"CV metrics report saved successfully at: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORGAN_MACCS_APF_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Features and target\n",
    "# ==========================\n",
    "# Pastikan x_morgan, x_maccs, x_apf, dan y sudah didefinisikan sebelumnya\n",
    "feature_sets = {\n",
    "    \"Morgan\": x_morgan,\n",
    "    \"MACCS\": x_maccs,\n",
    "    \"APF\": x_apf\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Hyperparameter grid SVM\n",
    "# ==========================\n",
    "paramgrid = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    \"gamma\": ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# Scoring function\n",
    "# ==========================\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# ==========================\n",
    "# CV setup\n",
    "# ==========================\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def calculate_ccr(sensitivity, specificity):\n",
    "    return (sensitivity + specificity) / 2\n",
    "\n",
    "# ==========================\n",
    "# Output folder\n",
    "# ==========================\n",
    "model_folder = r'C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# Loop untuk tiap feature set\n",
    "# ==========================\n",
    "for name, X in feature_sets.items():\n",
    "    print(f\"\\n===== Processing {name} features =====\")\n",
    "    \n",
    "    accuracies, auc_scores, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "    specificities, sensitivity_scores, ppvs, npvs, ccrs = [], [], [], [], []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(cv.split(X, y), total=10, desc=f\"{name} CV Folds\")):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            estimator=SVC(probability=True),\n",
    "            param_grid=paramgrid,\n",
    "            scoring=kappa_scorer,\n",
    "            cv=5,\n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Metrics\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_proba))\n",
    "        precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        confusion_matrices.append(cm)\n",
    "        \n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        \n",
    "        ppvs.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "        npvs.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "        ccrs.append(calculate_ccr(sensitivity, specificity))\n",
    "        \n",
    "        print(f\"Fold {fold+1} done. Best params: {grid.best_params_}\")\n",
    "    \n",
    "    # ==========================\n",
    "    # Report metrics\n",
    "    # ==========================\n",
    "    cv_metrics = {\n",
    "        \"Accuracy\": np.mean(accuracies),\n",
    "        \"AUC\": np.mean(auc_scores),\n",
    "        \"Precision\": np.mean(precisions),\n",
    "        \"Recall (Sensitivity)\": np.mean(sensitivity_scores),\n",
    "        \"F1\": np.mean(f1_scores),\n",
    "        \"Specificity\": np.mean(specificities),\n",
    "        \"PPV\": np.mean(ppvs),\n",
    "        \"NPV\": np.mean(npvs),\n",
    "        \"CCR\": np.mean(ccrs)\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== 10-Fold CV Metrics for {name} ===\")\n",
    "    for k, v in cv_metrics.items():\n",
    "        print(f'{k}: {v:.4f}')\n",
    "\n",
    "    # ==========================\n",
    "    # Train full dataset dengan best hyperparameter\n",
    "    # ==========================\n",
    "    print(f\"\\nTraining final SVM model on full dataset ({name} features)...\")\n",
    "    grid_final = GridSearchCV(\n",
    "        estimator=SVC(probability=True),\n",
    "        param_grid=paramgrid,\n",
    "        scoring=kappa_scorer,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_final.fit(X, y)\n",
    "    final_model = grid_final.best_estimator_\n",
    "    \n",
    "    # ==========================\n",
    "    # Save model & metrics\n",
    "    # ==========================\n",
    "    model_path = os.path.join(model_folder, f'Dermal_SVM_{name}.pkl')\n",
    "    joblib.dump(final_model, model_path, compress=9)\n",
    "    \n",
    "    metrics_df = pd.DataFrame([cv_metrics])\n",
    "    metrics_path = os.path.join(model_folder, f'Dermal_SVM_{name}_CV_metrics.xlsx')\n",
    "    metrics_df.to_excel(metrics_path, index=False)\n",
    "    \n",
    "    print(f\"Final SVM model for {name} saved at:\\n{model_path}\")\n",
    "    print(f\"CV metrics report saved at:\\n{metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Daftar file asli\n",
    "files = [\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_apf.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_maccs.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_xgb_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_apf.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_macckeys.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_rf_morgan.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_APF.pkl\",\n",
    "    r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Respiratory Irritation New\\Model\\final_SVM_MACCS.pkl\"\n",
    "]\n",
    "\n",
    "for filepath in files:\n",
    "    dir_name = os.path.dirname(filepath)\n",
    "    base_name = os.path.basename(filepath)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    \n",
    "    # Sisipkan \"Resp\" di awal nama file\n",
    "    new_name = f\"Resp_{name}{ext}\"\n",
    "    new_path = os.path.join(dir_name, new_name)\n",
    "    \n",
    "    os.rename(filepath, new_path)\n",
    "    print(f\"Renamed:\\n{filepath}\\n -> {new_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
