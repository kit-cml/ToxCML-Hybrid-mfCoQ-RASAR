{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0127edd-1625-4f25-9c48-78db2bf5209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Descriptors import MolLogP\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "import sys\n",
    "import multiprocessing\n",
    "from standardiser import break_bonds, neutralise, rules, unsalt\n",
    "from standardiser.utils import StandardiseException, sanity_check\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "def warn(*args, **kwargs):\n",
    "    pass \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn = warn\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import sys\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import csv\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import _pickle as cPickle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit    \n",
    "import bz2\n",
    "from glob import glob\n",
    "import _pickle as cPickle\n",
    "import pickle\n",
    "#Draw.DrawingOptions.atomLabelFontFace = \"DejaVu Sans\"\n",
    "#Draw.DrawingOptions.atomLabelFontSize = 18\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from CDK_pywrapper import CDK\n",
    "import pandas as pd\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "from rdkit.Chem import rdMolDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6c483-b4f2-4a5b-81fd-f1ce616caeec",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74997d-11fc-46b5-a02b-129d9f26cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolStandardize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Path input & output\n",
    "# ==========================\n",
    "raw_path = r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Original_dataset_acute dermal.xlsx\"\n",
    "out_path = r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Curated_dataset_acute_dermal.xlsx\"\n",
    "\n",
    "df = pd.read_excel(raw_path)\n",
    "\n",
    "# pastikan ada kolom SMILES dan Outcome\n",
    "assert \"SMILES\" in df.columns, \"Kolom SMILES tidak ditemukan\"\n",
    "assert \"Outcome\" in df.columns, \"Kolom Outcome tidak ditemukan\"\n",
    "\n",
    "# ==========================\n",
    "# RDKit standardization tools\n",
    "# ==========================\n",
    "normalizer = rdMolStandardize.Normalizer()\n",
    "reionizer = rdMolStandardize.Reionizer()\n",
    "tautomer_enumerator = rdMolStandardize.TautomerEnumerator()\n",
    "\n",
    "def standardize_smiles(smi):\n",
    "    \"\"\"QSAR-ready curation ala manuskrip: validasi, parent, normalisasi, tautomer, stereokimia sederhana.\"\"\"\n",
    "    if not isinstance(smi, str):\n",
    "        return None\n",
    "    smi = smi.strip()\n",
    "    if smi == \"\":\n",
    "        return None\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None  # struktural tidak valid → buang\n",
    "\n",
    "    # 1) Potong jadi parent (hapus counterion/solvent, ambil frag terbesar)\n",
    "    frags = Chem.GetMolFrags(mol, asMols=True, sanitize=False)\n",
    "    if len(frags) > 1:\n",
    "        # pilih frag dengan atom terbanyak\n",
    "        frags = sorted(frags, key=lambda m: m.GetNumAtoms(), reverse=True)\n",
    "        mol = frags[0]\n",
    "    else:\n",
    "        mol = frags[0]\n",
    "\n",
    "    # 2) Normalisasi & reionisasi (charge normalization, kekhususan fungsional)\n",
    "    try:\n",
    "        mol = normalizer.normalize(mol)\n",
    "        mol = reionizer.reionize(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Kekosongan stereokimia/tautomer: pilih bentuk kanonik\n",
    "    try:\n",
    "        mol = tautomer_enumerator.Canonicalize(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 4) SMILES kanonik\n",
    "    try:\n",
    "        can_smi = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return can_smi\n",
    "\n",
    "# ==========================\n",
    "# Terapkan kurasi ke seluruh dataset\n",
    "# ==========================\n",
    "curated_smiles = []\n",
    "valid_flags = []\n",
    "\n",
    "for smi in df[\"SMILES\"]:\n",
    "    cs = standardize_smiles(smi)\n",
    "    curated_smiles.append(cs)\n",
    "    valid_flags.append(cs is not None)\n",
    "\n",
    "df[\"Curated_SMILES\"] = curated_smiles\n",
    "df[\"Is_Valid\"] = valid_flags\n",
    "\n",
    "# buang struktur tidak valid\n",
    "df_valid = df[df[\"Is_Valid\"]].copy().reset_index(drop=True)\n",
    "\n",
    "# ==========================\n",
    "# Buang duplikat (canonical SMILES)\n",
    "# ==========================\n",
    "# jika ada konflik label, Anda bisa pilih aturan lain (mis. drop keduanya)\n",
    "dup_counts = df_valid[\"Curated_SMILES\"].value_counts()\n",
    "dups = dup_counts[dup_counts > 1].index.tolist()\n",
    "\n",
    "rows = []\n",
    "for smi in dups:\n",
    "    sub = df_valid[df_valid[\"Curated_SMILES\"] == smi]\n",
    "    if len(sub[\"Outcome\"].unique()) == 1:\n",
    "        # label konsisten → ambil satu saja\n",
    "        rows.append(sub.iloc[0])\n",
    "    else:\n",
    "        # label konflik → buang (sesuai manuskrip: records dengan label irreconcilable di-drop)[file:1]\n",
    "        continue\n",
    "\n",
    "df_unique = df_valid[df_valid[\"Curated_SMILES\"].isin(dup_counts[dup_counts == 1].index)].copy()\n",
    "if rows:\n",
    "    df_unique = pd.concat([df_unique, pd.DataFrame(rows)], axis=0, ignore_index=True)\n",
    "\n",
    "# drop kolom helper\n",
    "df_unique = df_unique.drop(columns=[\"Is_Valid\"]).rename(columns={\"Curated_SMILES\": \"SMILES_canonical\"})\n",
    "\n",
    "print(\"Sebelum kurasi:\", len(df), \"baris\")\n",
    "print(\"Setelah validasi & deduplikasi:\", len(df_unique), \"baris\")\n",
    "\n",
    "# ==========================\n",
    "# Simpan hasil kurasi\n",
    "# ==========================\n",
    "df_unique.to_excel(out_path, index=False)\n",
    "print(\"Curated dataset disimpan di:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b272cb-65fc-43b9-a822-83671caeb22f",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14da0ca-a0d6-49c2-8e18-eb2896fafca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# Load dataset\n",
    "# ==========================\n",
    "file_path = r\"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Original_dataset_acute dermal.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Kolom dataset:\", df.columns)\n",
    "\n",
    "smiles_all = df[\"SMILES\"].astype(str).values\n",
    "\n",
    "# ==========================\n",
    "# Fungsi: Bemis–Murcko scaffold\n",
    "# ==========================\n",
    "def get_bemis_murcko_scaffold(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    scaff = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    return Chem.MolToSmiles(scaff) if scaff is not None else None\n",
    "\n",
    "# Hitung scaffold untuk semua molekul\n",
    "scaffolds = [get_bemis_murcko_scaffold(smi) for smi in smiles_all]\n",
    "\n",
    "# Group index per scaffold\n",
    "scaf_to_idx = {}\n",
    "for idx, scaf in enumerate(scaffolds):\n",
    "    scaf_to_idx.setdefault(scaf, []).append(idx)\n",
    "\n",
    "unique_scaffolds = list(scaf_to_idx.keys())\n",
    "rng = np.random.RandomState(42)\n",
    "rng.shuffle(unique_scaffolds)\n",
    "\n",
    "# ==========================\n",
    "# Scaffold-based 80:20 split\n",
    "# ==========================\n",
    "train_idx = []\n",
    "test_idx = []\n",
    "n_total = len(df)\n",
    "target_train = 0.8 * n_total\n",
    "current_train = 0\n",
    "\n",
    "for scaf in unique_scaffolds:\n",
    "    idxs = scaf_to_idx[scaf]\n",
    "    if current_train + len(idxs) <= target_train:\n",
    "        train_idx.extend(idxs)\n",
    "        current_train += len(idxs)\n",
    "    else:\n",
    "        test_idx.extend(idxs)\n",
    "\n",
    "train_idx = np.array(train_idx, dtype=int)\n",
    "test_idx = np.array(test_idx, dtype=int)\n",
    "\n",
    "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# ==========================\n",
    "# Save hasil split\n",
    "# ==========================\n",
    "folder = os.path.dirname(file_path)\n",
    "train_file = os.path.join(folder, \"Train_set_acute_dermal_scaffoldsplit.xlsx\")\n",
    "test_file = os.path.join(folder, \"Test_set_acute_dermal_scaffoldsplit.xlsx\")\n",
    "\n",
    "train_df.to_excel(train_file, index=False)\n",
    "test_df.to_excel(test_file, index=False)\n",
    "\n",
    "print(f\"Train set disimpan di: {train_file}\")\n",
    "print(f\"Test set disimpan di: {test_file}\")\n",
    "print(f\"Total sampel: {n_total}, Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "print(\"\\nDistribusi Outcome Train:\")\n",
    "print(train_df[\"Outcome\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribusi Outcome Test:\")\n",
    "print(test_df[\"Outcome\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a4d73-926e-4314-9653-8171be11f0be",
   "metadata": {},
   "source": [
    "# FINGEPRINTS COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89687f6-a45c-4773-a31a-113ac3f4eeb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung Morgan Descriptors\n",
    "def compute_morgan_fp(smiles, radius=2, n_bits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return list(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits))\n",
    "    return [0] * n_bits  # Jika gagal, kembalikan vektor nol\n",
    "\n",
    "# Fungsi untuk menghitung MACCS Keys\n",
    "def compute_maccs_fp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return list(MACCSkeys.GenMACCSKeys(mol))\n",
    "    return [0] * 167  # MACCS memiliki 167 bit\n",
    "\n",
    "# Fungsi APF bit vector\n",
    "def compute_apf_fp(smiles, n_bits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        fp = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=n_bits)\n",
    "        return list(fp)\n",
    "    return [0] * n_bits\n",
    "\n",
    "# Daftar file input\n",
    "input_files = [\n",
    "    \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Test_set.xlsx\",\n",
    "    \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Train_set.xlsx\"\n",
    "]\n",
    "\n",
    "\n",
    "# Proses setiap file input\n",
    "for input_path in input_files:\n",
    "    # Load dataset\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # Hitung fitur untuk setiap molekul\n",
    "    df[\"Morgan_Descriptors\"] = df[\"SMILES\"].apply(compute_morgan_fp)\n",
    "    df[\"MACCS_Descriptors\"] = df[\"SMILES\"].apply(compute_maccs_fp)\n",
    "    df[\"APF_Descriptors\"] = df[\"SMILES\"].apply(compute_apf_fp)\n",
    "\n",
    "    # Urutkan berdasarkan kolom Outcome\n",
    "    df_sorted = df.sort_values(by=\"Outcome\", ascending=True)\n",
    "\n",
    "    # Tentukan output path (folder sama dengan input)\n",
    "    folder = os.path.dirname(input_path)\n",
    "    filename = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    output_path = os.path.join(folder, f\"{filename}_with_fingerprints_sorted.xlsx\")\n",
    "\n",
    "    # Simpan hasil\n",
    "    df_sorted.to_excel(output_path, index=False)\n",
    "    print(f\"Hasil untuk '{input_path}' telah disimpan ke '{output_path}'.\")\n",
    "\n",
    "print(\"Selesai memproses semua file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d39922-93ec-4c99-b857-62631267019b",
   "metadata": {},
   "source": [
    "# RDKIT-CDK COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14e7bc-1500-4b84-8fa2-243b3cd3f12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fungsi bantu konversi SMILES ke Mol RDKit\n",
    "def smiles_to_mol(smiles):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(smiles)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Fungsi hitung deskriptor RDKit\n",
    "def calculate_rdkit_descriptors(mol):\n",
    "    columns = [\n",
    "        'Molecular Weight', 'logP', 'LabuteASA', 'TPSA', 'AMW', 'NumRotatableBonds',\n",
    "        'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings', 'NumAromaticHeterocycles',\n",
    "        'NumSaturatedHeterocycles', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles',\n",
    "        'NumSaturatedCarbocycles', 'NumAliphaticCarbocycles', 'FractionCSP3',\n",
    "        'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Chi4v',\n",
    "        'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n',\n",
    "        'HallKierAlpha',\n",
    "        \"Heavy Atom Count\", \"Ring Count\", \"Num H Donors\", \"Num H Acceptors\"\n",
    "    ]\n",
    "    if mol is None:\n",
    "        return {col: None for col in columns}\n",
    "    return {\n",
    "        'Molecular Weight': Descriptors.MolWt(mol),\n",
    "        'logP': Descriptors.MolLogP(mol),\n",
    "        'LabuteASA': rdMolDescriptors.CalcLabuteASA(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol),\n",
    "        'AMW': Descriptors.MolWt(mol),\n",
    "        'NumRotatableBonds': Descriptors.NumRotatableBonds(mol),\n",
    "        'NumAromaticRings': Descriptors.NumAromaticRings(mol),\n",
    "        'NumSaturatedRings': Descriptors.NumSaturatedRings(mol),\n",
    "        'NumAliphaticRings': Descriptors.NumAliphaticRings(mol),\n",
    "        'NumAromaticHeterocycles': Descriptors.NumAromaticHeterocycles(mol),\n",
    "        'NumSaturatedHeterocycles': Descriptors.NumSaturatedHeterocycles(mol),\n",
    "        'NumAliphaticHeterocycles': Descriptors.NumAliphaticHeterocycles(mol),\n",
    "        'NumAromaticCarbocycles': Descriptors.NumAromaticCarbocycles(mol),\n",
    "        'NumSaturatedCarbocycles': Descriptors.NumSaturatedCarbocycles(mol),\n",
    "        'NumAliphaticCarbocycles': Descriptors.NumAliphaticCarbocycles(mol),\n",
    "        'FractionCSP3': Descriptors.FractionCSP3(mol),\n",
    "        'Chi0v': Descriptors.Chi0v(mol),\n",
    "        'Chi1v': Descriptors.Chi1v(mol),\n",
    "        'Chi2v': Descriptors.Chi2v(mol),\n",
    "        'Chi3v': Descriptors.Chi3v(mol),\n",
    "        'Chi4v': Descriptors.Chi4v(mol),\n",
    "        'Chi1n': Descriptors.Chi1n(mol),\n",
    "        'Chi2n': Descriptors.Chi2n(mol),\n",
    "        'Chi3n': Descriptors.Chi3n(mol),\n",
    "        'Chi4n': Descriptors.Chi4n(mol),\n",
    "        'HallKierAlpha': Descriptors.HallKierAlpha(mol),\n",
    "        'Heavy Atom Count': Descriptors.HeavyAtomCount(mol),\n",
    "        'Ring Count': Descriptors.RingCount(mol),\n",
    "        'Num H Donors': Descriptors.NumHDonors(mol),\n",
    "        'Num H Acceptors': Descriptors.NumHAcceptors(mol)\n",
    "    }\n",
    "\n",
    "# Inisialisasi CDK\n",
    "cdk = CDK()\n",
    "\n",
    "# List file input\n",
    "input_files = [\n",
    "    \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Train_set_with_fingerprints_sorted.xlsx\",\n",
    "    \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Acute Dermal Toxicity (manual split)\\Test_set_with_fingerprints_sorted.xlsx\"\n",
    "\n",
    "]\n",
    "\n",
    "# Fitur CDK yang ingin diambil\n",
    "cdk_features = [\n",
    "    'ALogP', 'ALogp2', 'AMR', 'MLogP', 'nAtomP', 'naAromAtom', 'bpol',\n",
    "    'nB', 'ECCEN', 'fragC', 'nHBAcc', 'nHBDon', 'nAtomLAC', 'nAtomLC',\n",
    "    'PetitjeanNumber', 'nRotB', 'LipinskiFailures', 'TopoPSA', 'VAdjMat',\n",
    "    'XLogP', 'Fsp3'\n",
    "]\n",
    "\n",
    "# Proses setiap file\n",
    "for input_path in input_files:\n",
    "    # Baca data\n",
    "    df = pd.read_excel(input_path)\n",
    "    \n",
    "    # Buat Mol RDKit\n",
    "    df['Mol'] = df['SMILES'].apply(smiles_to_mol)\n",
    "    \n",
    "    # Hitung deskriptor RDKit\n",
    "    df['RDKit_Descriptors'] = df['Mol'].apply(calculate_rdkit_descriptors)\n",
    "    \n",
    "    # Ekspansi dict RDKit ke kolom\n",
    "    rdkit_df = pd.json_normalize(df['RDKit_Descriptors'])\n",
    "    \n",
    "    # Hitung fitur CDK\n",
    "    cdk_descriptors = cdk.calculate(df['Mol'])\n",
    "    cdk_df = cdk_descriptors[cdk_features].reset_index(drop=True)\n",
    "    \n",
    "    # Gabungkan semua fitur ke DataFrame utama\n",
    "    df_final = pd.concat([df.drop(columns=['Mol', 'RDKit_Descriptors']), rdkit_df, cdk_df], axis=1)\n",
    "    \n",
    "    # Tentukan output path\n",
    "    output_path = input_path.replace('.xlsx', '_with_RDKit_and_CDK_features.xlsx')\n",
    "    \n",
    "    # Simpan hasil\n",
    "    df_final.to_excel(output_path, index=False)\n",
    "    print(f\"Dataset '{input_path}' dengan RDKit + CDK features sudah disimpan di:\\n{output_path}\")\n",
    "\n",
    "print(\"Selesai memproses semua file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68120b3-3cd3-4d35-94e3-10e31f151c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List file input Excel\n",
    "input_files = [\n",
    "   \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Carcinogencity (manual split)\\Dataset\\Train_set_Carcinogenicity_with_fingerprints_sorted_with_RDKit_and_CDK_features.xlsx\", \n",
    "    \"C:\\Fauzan\\Manuskrip QSAR 1\\Major Revision\\Carcinogencity (manual split)\\Dataset\\Test_set_Carcinogenicity_with_fingerprints_sorted_with_RDKit_and_CDK_features.xlsx\"]\n",
    "\n",
    "\n",
    "for file_path in input_files:\n",
    "    # Baca Excel\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Pastikan kolom 'Outcome' ada\n",
    "    if 'Outcome' not in df.columns:\n",
    "        print(f\"Kolom 'Outcome' tidak ditemukan di {file_path}.\")\n",
    "        continue\n",
    "    \n",
    "    # Informasi dasar\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(f\"Total data: {len(df)}\")\n",
    "    print(\"Distribusi Outcome:\")\n",
    "    print(df['Outcome'].value_counts())\n",
    "    \n",
    "    # Visualisasi distribusi Outcome\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df['Outcome'].value_counts().plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'Distribusi Outcome - {file_path.split(\"\\\\\")[-1]}')\n",
    "    plt.xlabel('Outcome')\n",
    "    plt.ylabel('Frekuensi')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99324e7c-2789-4e5d-b2a6-f4ca8df9325d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
